using BEPUutilities2.Collections;
using BEPUutilities2.Memory;
using SolverPrototype.Collidables;
using System.Numerics;
using System.Runtime.CompilerServices;
using System.Runtime.InteropServices;
using System;
using SolverPrototype.Constraints;
using System.Diagnostics;
using System.Threading;
using BEPUutilities2;

namespace SolverPrototype.CollisionDetection
{
    /*
     * The narrow phase operates on overlaps generated by the broad phase. 
     * Its job is to compute contact manifolds for overlapping collidables and to manage the constraints produced by those manifolds. 
     * 
     * The scheduling of collision detection jobs is conceptually asynchronous. There is no guarantee that a broad phase overlap provided to the narrow phase
     * will result in an immediate calculation of the manifold. This is useful for batching together many collidable pairs of the same type for simultaneous SIMD-friendly execution.
     * (Not all pairs are ideal fits for wide SIMD, but many common and simple ones are.)
     * 
     * The interface to the broad phase makes no guarantees about the nature of this batching. The narrow phase could immediately execute, or it could batch up Vector<float>.Count,
     * or maybe 32 in a row, or it could wait until all overlaps have been submitted before actually beginning work.
     * 
     * This deferred execution requires that the pending work be stored somehow. This is complicated by the fact that there are a variety of different top level pairs that handle
     * incoming contact manifold data and the resulting constraints in different ways. There are two main distinctions:
     * 1) Continuous collision detection mode. For the purposes of the narrow phase, each collidable can be thought of as discrete, inner sphere, substepping, or inner sphere + substepping.
     * -Discrete pairs take the result of the underlying manifold and directly manipulate regular contact constraints. 
     * -Inner sphere pairs, with sufficient relative linear velocity, can create one or two additional sphere-convex pairs per convex pair.
     * -Substepping pairs potentially generate a bunch of child pairs, depending on the collidable velocities, and then choose from the resulting manifolds. 
     * Once the best manifold is selected, constraint management is similar to the discrete case.
     * -Inner sphere + substepping pairs just do both of the above.
     * 2) Individual versus compound types. Compound pairs will tend to create child convex pairs and wait for their completion. This ensures the greatest number of simultaneous
     * SIMD-friendly manifold calculations. For example, four compound-compound pairs could result in 60 sphere-capsule subpairs which can then all be executed in a SIMD fashion.
     * 
     * These two build on each other- a compound-compound pair with inner sphere enabled will want to generate both the inner sphere pairs and the regular pairs simultaneously to avoid 
     * traversing any acceleration structures multiple times.
     * 
     * Note that its possible for the evaluation of a pair to generate more pairs. This is most easily seen in compound pairs or substep pairs, but we do permit less obvious cases.
     * For example, a potential optimization for substepping is only do as many substeps as are needed to find the first manifold with approaching contacts (or some other heuristic).
     * In order for such an optimization to be used, we must be willing to spawn more pairs if the first set of substeps we did didn't find any heuristically accepted manifolds.
     * In the limit, that would mean doing one substep at a time. (In practice, we'd probably just try to fill up the remainder of a SIMD batch.)
     * 
     * Another example: imagine a high-complexity convex-convex test that has highly divergent execution, but with smaller pieces which are not as divergent.
     * SIMD operations don't map well to divergent execution, so if the individual jobs are large enough, it could be worth it to spawn new pairs for the nondivergent pieces.
     * Most convexes aren't complicated enough to warrant this (often it's faster to simply execute all paths), but it may be relevant in the convex hull versus convex hull case.
     * 
     * In any case where more pairs are generated, evaluating just the current set of pairs is insufficient to guarantee completion. Instead, execution can be thought of like traversing a graph.
     * Each work-creating pair may create an entry on the execution stack if its 'execution threshold' is reached (the arbitrary size which, when reached, results in the execution of the 
     * stored pairs). When no jobs remain on the stack, take any available stored pair set and try to execute it- even if it hasn't yet reached its execution threshold. In this situation,
     * without further action it won't ever fill up, so there's no reason to wait. That execution may then spawn more work, which could create an element on the execution stack, and so on. 
     * Ideally, job sets are consumed in order of their probability of creating new work. That maximizes the number of SIMD-friendly executions.
     * 
     * In practice, there are two phases. The first phase takes in the broad phase-generated top level pairs. At this stage, we do not need to resort to executing incomplete bundles. 
     * Instead, we just continue to work on the top level pairs until none remain. The second phase kicks in here. Since no further top-level work is being generated, we start trying to 
     * flush all the remaining pairs, even if they are not at the execution threshold, as in the above traverse-and-reset approach.
     * 
     * All of the above works within the context of a single thread. There may be many threads in flight, but each one is guaranteed to be handling different top level pairs.
     * That means all of the pair storage is thread local and requires no synchronization. It is also mostly ephemeral- once the thread finishes, only a small amount of information needs
     * to be persisted to globally accessed memory. (Overlap->ConstraintHandle is one common piece of data, but some pairs may also persist other data like separating axes for early outs.
     * Such extra data is fairly rare, since it implies divergence in execution- which is something you don't want in a SIMD-friendly implementation. Likely only in things like hull-hull.)
     * 
     * Every narrow phase pair is responsible for managing the constraints that its computed manifolds require. 
     * This requires the ability to look up existing overlap->constraint relationships for three reasons:
     * 1) Any existing constraint, if it has the same number of contacts as the new manifold, should have its contact data updated.
     * 2) Any accumulated impulse from the previous frame's contact solve should be distributed over the new set of contacts for warm starting this frame's solve.
     * 3) Any change in contact count should result in the removal of the previous constraint (if present) and the addition of the new constraint (if above zero contacts).
     * This mapping is stored in a single dictionary. The previous frame's mapping is treated as read-only during the new frame's narrow phase execution, 
     * //so no synchronization is required to read it. The current frame updates pointerse in the dictionary and collects deferred adds on each worker thread for later flushing.
     * 
     * Constraints associated with 'stale' overlaps (those which were not updated during the current frame) are removed in a postpass.
     * 
     */




    public abstract class NarrowPhase
    {
        public BufferPool Pool;
        public Bodies Bodies;
        public Solver Solver;
        public Shapes Shapes;
        public CollisionTaskRegistry CollisionTaskRegistry;
        public ConstraintRemover ConstraintRemover;
        public FreshnessChecker FreshnessChecker;
        //TODO: It is possible that some types will benefit from per-overlap data, like separating axes. For those, we should have type-dedicated overlap dictionaries.
        //The majority of type pairs, however, only require a constraint handle.
        public PairCache PairCache;

        protected NarrowPhase()
        {
            flushWorkerLoop = FlushWorkerLoop;
        }

        public void Prepare(IThreadDispatcher threadDispatcher = null)
        {
            OnPrepare(threadDispatcher);
            PairCache.Prepare(threadDispatcher);
            ConstraintRemover.Prepare(threadDispatcher);
        }

        protected abstract void OnPrepare(IThreadDispatcher threadDispatcher);
        protected abstract void OnFlush(IThreadDispatcher threadDispatcher);

        int flushJobIndex;
        QuickList<NarrowPhaseFlushJob, Buffer<NarrowPhaseFlushJob>> flushJobList;
        Action<int> flushWorkerLoop;
        void FlushWorkerLoop(int workerIndex)
        {
            int jobIndex;
            while ((jobIndex = Interlocked.Increment(ref flushJobIndex)) < flushJobList.Count)
            {
                ExecuteFlushJob(ref flushJobList[jobIndex]);
            }
        }

        void ExecuteFlushJob(ref NarrowPhaseFlushJob job)
        {
            switch (job.Type)
            {
                case NarrowPhaseFlushJobType.RemoveConstraintsFromBodyLists:
                    ConstraintRemover.RemoveConstraintsFromBodyLists();
                    break;
                case NarrowPhaseFlushJobType.RemoveConstraintFromTypeBatch:
                    ConstraintRemover.RemoveConstraintsFromTypeBatch(job.Index);
                    break;
                case NarrowPhaseFlushJobType.RemoveBodyHandlesFromBatches:
                    ConstraintRemover.RemoveBodyHandlesFromBatches();
                    break;
                case NarrowPhaseFlushJobType.ReturnConstraintHandlesToPool:
                    ConstraintRemover.ReturnConstraintHandlesToPool();
                    break;
                case NarrowPhaseFlushJobType.FlushPairCacheChanges:
                    PairCache.FlushMappingChanges();
                    break;
            }

        }

        public void Flush(IThreadDispatcher threadDispatcher = null)
        {
            FreshnessChecker.CheckFreshness(threadDispatcher);

            //Given the sizes involved, a fixed guess of 128 should be just fine for essentially any simulation. Overkill, but not in a concerning way.
            //Temporarily allocating 1KB of memory isn't a big deal, and we will only touch the necessary subset of it anyway.
            //(There are pathological cases where resizes are still possible, but the constraint remover handles them by not adding unsafely.)
            QuickList<NarrowPhaseFlushJob, Buffer<NarrowPhaseFlushJob>>.Create(Pool.SpecializeFor<NarrowPhaseFlushJob>(), 128, out flushJobList);
            PairCache.PrepareFlushJobs(ref flushJobList);
            ConstraintRemover.CreateFlushJobs(ref flushJobList);

            if (threadDispatcher == null)
            {
                for (int i = 0; i < flushJobList.Count; ++i)
                {
                    ExecuteFlushJob(ref flushJobList[i]);
                }
            }
            else
            {
                flushJobIndex = -1;
                threadDispatcher.DispatchWorkers(flushWorkerLoop);
            }
            flushJobList.Dispose(Pool.SpecializeFor<NarrowPhaseFlushJob>());

            PairCache.Postflush();
            ConstraintRemover.Postflush();

            OnFlush(threadDispatcher);
        }

        public void Dispose()
        {
            PairCache.Dispose();
            OnDispose();
        }

        protected abstract void OnDispose();

        //TODO: Configurable memory usage. It automatically adapts based on last frame state, but it's nice to be able to specify minimums when more information is known.

    }


    /// <summary>
    /// Turns broad phase overlaps into contact manifolds and uses them to manage constraints in the solver.
    /// </summary>
    /// <typeparam name="TCallbacks">Type of the callbacks to use.</typeparam>
    public partial class NarrowPhase<TCallbacks> : NarrowPhase where TCallbacks : struct, INarrowPhaseCallbacks
    {
        public TCallbacks Callbacks;

        public NarrowPhase(Simulation simulation, CollisionTaskRegistry collisionTaskRegistry, TCallbacks callbacks,
             int minimumMappingSize = 2048, int minimumPendingSize = 128, int minimumPerTypeCapacity = 128)
            : base()
        {
            Pool = simulation.BufferPool;
            Bodies = simulation.Bodies;
            Solver = simulation.Solver;
            Callbacks = callbacks;
            Callbacks.Initialize(simulation);
            CollisionTaskRegistry = collisionTaskRegistry;
            PairCache = new PairCache(simulation.BufferPool, minimumMappingSize, minimumPendingSize, minimumPerTypeCapacity);
            ConstraintRemover = new ConstraintRemover(simulation.BufferPool, simulation.Bodies, simulation.Solver, simulation.ConstraintGraph, minimumRemovalCapacity: minimumPendingSize);
            FreshnessChecker = new FreshnessChecker(this);
        }

        protected override void OnPrepare(IThreadDispatcher threadDispatcher)
        {
            PrepareOverlapWorkers(threadDispatcher);
        }

        protected override void OnFlush(IThreadDispatcher threadDispatcher)
        {
            //TODO: Constraint generators can actually be disposed immediately once the overlap finding process completes.
            //Here, we are disposing them late- that means we suffer a little more wasted memory use. 
            //If you actually wanted to address this, you could add in an OnPreflush or similar.
            DisposeConstraintGenerators(threadDispatcher == null ? 1 : threadDispatcher.ThreadCount);
            Callbacks.Flush(threadDispatcher);
        }

        protected override void OnDispose()
        {
            Callbacks.Dispose();
        }

        public unsafe void HandleOverlap(int workerIndex, CollidableReference a, CollidableReference b)
        {
            if (!Callbacks.AllowContactGeneration(workerIndex, a, b))
                return;
            var staticness = (a.packed >> 31) | ((b.packed & 0x7FFFFFFF) >> 30);
            ref var overlapWorker = ref overlapWorkers[workerIndex];
            var pair = new CollidablePair(a, b);
            switch (staticness)
            {
                case 0:
                    {
                        //Both references are bodies.
                        //This is a body. In order to dispatch it properly, we need to know some metadata.
                        //TODO: Once inactive bodies exist, this will need to be updated.
                        var bodyIndexA = Bodies.HandleToIndex[a.Collidable];
                        var bodyIndexB = Bodies.HandleToIndex[b.Collidable];
                        ref var aCollidable = ref Bodies.Collidables[bodyIndexA];
                        ref var bCollidable = ref Bodies.Collidables[bodyIndexB];
                        Bodies.GetPoseByIndex(bodyIndexA, out var poseA);
                        Bodies.GetPoseByIndex(bodyIndexB, out var poseB);
                        var shapeTypeA = aCollidable.Shape.Type;
                        var shapeTypeB = bCollidable.Shape.Type;
                        Shapes[shapeTypeA].GetShapeData(aCollidable.Shape.Index, out var shapePointerA, out var shapeSizeA);
                        Shapes[shapeTypeB].GetShapeData(aCollidable.Shape.Index, out var shapePointerB, out var shapeSizeB);
                        //Note that we never create 'unilateral' CCD pairs. That is, if either collidable in a pair enables a CCD feature, we just act like both are using it.
                        //That keeps things a little simpler. Unlike v1, we don't have to worry about the implications of 'motion clamping' here- no need for deeper configuration.
                        var useSubstepping = aCollidable.Continuity.UseSubstepping || bCollidable.Continuity.UseSubstepping;
                        var useInnerSphere = aCollidable.Continuity.UseInnerSphere || bCollidable.Continuity.UseInnerSphere;
                        //Create a continuation for the pair given the CCD state.
                        if (useSubstepping && useInnerSphere)
                        {
                        }
                        else if (useSubstepping)
                        {

                        }
                        else if (useInnerSphere)
                        {

                        }
                        else
                        {
                            //This pair uses no CCD beyond its speculative margin.
                            var continuation = overlapWorker.ConstraintGenerators.AddDiscrete(ref pair);
                            overlapWorker.Batcher.Add(shapeTypeA, shapeTypeB, shapeSizeA, shapeSizeB, shapePointerA, shapePointerB, ref poseA, ref poseB, continuation,
                                ref overlapWorker.ConstraintGenerators, ref overlapWorker.Filters);
                        }

                        //Pull the velocity information for all involved bodies. We will request a number of steps that will cover the motion path.
                        //number of substeps = min(maximum substep count, 1 + floor(estimated displacement / step length)), where
                        //estimated displacement = dt * (length(linear velocity A - linear velocity B) +
                        //                               maximum radius A * (length(angular velocity A) + maximum radius B * length(angular velocity B)) 
                        //Once we have a number of 
                        //We use the minimum step length of each contributing collidable. Treat non-substepping collidables as having a step length of infinity.
                        var stepLengthA = aCollidable.Continuity.UseSubstepping ? aCollidable.Continuity.MaximumStepLength : float.MaxValue;
                        var stepLengthB = bCollidable.Continuity.UseSubstepping ? bCollidable.Continuity.MaximumStepLength : float.MaxValue;
                        float stepLength = stepLengthA < stepLengthB ? stepLengthA : stepLengthB;

                    }
                    break;
                case 1:
                    {
                        //Collidable a is a body, b is a static.
                        //TODO: Once non-body collidables exist, this will need to be updated.
                    }
                    break;
                case 2:
                    {
                        //Collidable a is a static, b is a body.
                        //TODO: Once non-body collidables exist, this will need to be updated.
                    }
                    break;
                case 3:
                    {
                        //Both collidables are statics. This is a bit of a weird situation- under normal conditions, static bodies will belong to the 
                        //'inactive' broad phase tree, and the inactive tree is not tested against itself. The user must have configured this static to be in the active tree to act
                        //as a detector or something along those lines.
                        //TODO: Once non-body collidables exist, this will need to be updated.
                    }
                    break;
            }

        }
    }
}